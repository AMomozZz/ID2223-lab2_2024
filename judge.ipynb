{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets (from -r requirements.txt (line 1))\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting flow_judge (from -r requirements.txt (line 2))\n",
      "  Using cached flow_judge-0.1.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting filelock (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy>=1.17 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached pyarrow-18.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting requests>=2.32.2 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 1))\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached aiohttp-3.11.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/lab/lib/python3.12/site-packages (from datasets->-r requirements.txt (line 1)) (24.2)\n",
      "Collecting pyyaml>=5.1 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pydantic>=2.9.1 (from flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting hf-transfer>=0.1.1 (from flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached hf_transfer-0.1.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ipykernel>=6.29.0 in /opt/conda/envs/lab/lib/python3.12/site-packages (from flow_judge->-r requirements.txt (line 2)) (6.29.5)\n",
      "Collecting ipywidgets>=8.1.0 (from flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting structlog (from flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached structlog-24.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting vllm==0.6.2 (from flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached vllm-0.6.2-cp38-abi3-manylinux1_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/lab/lib/python3.12/site-packages (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (6.1.0)\n",
      "Collecting sentencepiece (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting numpy>=1.17 (from datasets->-r requirements.txt (line 1))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting py-cpuinfo (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.45.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tokenizers>=0.19.1 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting protobuf (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting openai>=1.40.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached openai-1.57.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn[standard] (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pillow (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting prometheus-client>=0.18.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting lm-format-enforcer==0.10.6 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting outlines<0.1,>=0.0.43 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10 in /opt/conda/envs/lab/lib/python3.12/site-packages (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (4.12.2)\n",
      "Collecting partial-json-parser (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached partial_json_parser-0.2.1.1.post4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/lab/lib/python3.12/site-packages (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (26.2.0)\n",
      "Collecting msgspec (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached msgspec-0.18.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf==0.10.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/lab/lib/python3.12/site-packages (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (8.5.0)\n",
      "Collecting mistral-common>=1.4.3 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached mistral_common-1.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting einops (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting ray>=2.9 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached ray-2.40.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting nvidia-ml-py (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch==2.4.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.19 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting xformers==0.0.27.post2 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached xformers-0.0.27.post2-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/conda/envs/lab/lib/python3.12/site-packages (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: setuptools>=74.1.1 in /opt/conda/envs/lab/lib/python3.12/site-packages (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (75.6.0)\n",
      "Collecting fastapi>=0.114.1 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets->-r requirements.txt (line 1))\n",
      "  Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (1.8.9)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (8.30.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.1.0->flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets>=8.1.0->flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.1->flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.9.1->flow_judge->-r requirements.txt (line 2))\n",
      "  Using cached pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets->-r requirements.txt (line 1))\n",
      "  Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets->-r requirements.txt (line 1))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets->-r requirements.txt (line 1))\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets->-r requirements.txt (line 1))\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/lab/lib/python3.12/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets->-r requirements.txt (line 1))\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets->-r requirements.txt (line 1))\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.114.1->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /opt/conda/envs/lab/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/envs/lab/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (4.3.6)\n",
      "Collecting jsonschema<5.0.0,>=4.21.1 (from mistral-common>=1.4.3->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting pillow (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting tiktoken>=0.6.0 (from vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached tiktoken-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=1.40.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.40.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.40.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.40.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached jiter-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai>=1.40.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting lark (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting cloudpickle (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting numba (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting referencing (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pycountry (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyairports (from outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting click>=7.0 (from ray>=2.9->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.6.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.45.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/lab/lib/python3.12/site-packages (from importlib-metadata->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3)) (3.21.0)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached watchfiles-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached websockets-14.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.40.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/envs/lab/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.8.4)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.3->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.3->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/lab/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/lab/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.2.13)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->outlines<0.1,>=0.0.43->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/lab/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/lab/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/envs/lab/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.29.0->flow_judge->-r requirements.txt (line 2)) (0.2.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.0->vllm==0.6.2->flow_judge[vllm]->-r requirements.txt (line 3))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Using cached flow_judge-0.1.2-py3-none-any.whl (81 kB)\n",
      "Using cached vllm-0.6.2-cp38-abi3-manylinux1_x86_64.whl (228.3 MB)\n",
      "Using cached gguf-0.10.0-py3-none-any.whl (71 kB)\n",
      "Using cached lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
      "Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
      "Using cached torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
      "Using cached xformers-0.0.27.post2-cp312-cp312-manylinux2014_x86_64.whl (20.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached aiohttp-3.11.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached hf_transfer-0.1.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached pyarrow-18.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "Using cached pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Using cached pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached structlog-24.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached mistral_common-1.5.1-py3-none-any.whl (6.5 MB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached openai-1.57.0-py3-none-any.whl (389 kB)\n",
      "Using cached outlines-0.0.46-py3-none-any.whl (101 kB)\n",
      "Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Using cached prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached ray-2.40.0-cp312-cp312-manylinux2014_x86_64.whl (67.0 MB)\n",
      "Using cached protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached tiktoken-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached msgspec-0.18.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Using cached nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
      "Using cached partial_json_parser-0.2.1.1.post4-py3-none-any.whl (9.9 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "Using cached httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Using cached jiter-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Using cached uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached watchfiles-1.0.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Using cached websockets-14.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numba-0.60.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "Using cached pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached llvmlite-0.43.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: sentencepiece, pytz, pyairports, py-cpuinfo, nvidia-ml-py, mpmath, xxhash, widgetsnbextension, websockets, uvloop, urllib3, tzdata, tqdm, sympy, structlog, sniffio, safetensors, rpds-py, regex, pyyaml, python-dotenv, pydantic-core, pycountry, pyarrow, protobuf, propcache, prometheus-client, pillow, partial-json-parser, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, msgspec, msgpack, MarkupSafe, llvmlite, lark, jupyterlab-widgets, jiter, interegular, idna, httptools, hf-transfer, h11, fsspec, frozenlist, filelock, einops, distro, diskcache, dill, cloudpickle, click, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, uvicorn, triton, requests, referencing, pydantic, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, multiprocess, jinja2, httpcore, gguf, anyio, aiosignal, watchfiles, tiktoken, starlette, nvidia-cusolver-cu12, lm-format-enforcer, jsonschema-specifications, ipywidgets, huggingface-hub, httpx, aiohttp, torch, tokenizers, prometheus-fastapi-instrumentator, openai, jsonschema, flow_judge, fastapi, xformers, transformers, torchvision, ray, mistral-common, datasets, outlines, vllm\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.7.0 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 cloudpickle-3.1.0 datasets-3.1.0 dill-0.3.8 diskcache-5.6.3 distro-1.9.0 einops-0.8.0 fastapi-0.115.6 filelock-3.16.1 flow_judge-0.1.2 frozenlist-1.5.0 fsspec-2024.9.0 gguf-0.10.0 h11-0.14.0 hf-transfer-0.1.8 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.0 huggingface-hub-0.26.3 idna-3.10 interegular-0.3.3 ipywidgets-8.1.5 jinja2-3.1.4 jiter-0.8.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyterlab-widgets-3.0.13 lark-1.2.2 llvmlite-0.43.0 lm-format-enforcer-0.10.6 mistral-common-1.5.1 mpmath-1.3.0 msgpack-1.1.0 msgspec-0.18.6 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 numba-0.60.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.560.30 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 openai-1.57.0 outlines-0.0.46 pandas-2.2.3 partial-json-parser-0.2.1.1.post4 pillow-10.4.0 prometheus-client-0.21.1 prometheus-fastapi-instrumentator-7.0.0 propcache-0.2.1 protobuf-5.29.1 py-cpuinfo-9.0.0 pyairports-2.1.1 pyarrow-18.1.0 pycountry-24.6.1 pydantic-2.10.3 pydantic-core-2.27.1 python-dotenv-1.0.1 pytz-2024.2 pyyaml-6.0.2 ray-2.40.0 referencing-0.35.1 regex-2024.11.6 requests-2.32.3 rpds-py-0.22.3 safetensors-0.4.5 sentencepiece-0.2.0 sniffio-1.3.1 starlette-0.41.3 structlog-24.4.0 sympy-1.13.3 tiktoken-0.7.0 tokenizers-0.21.0 torch-2.4.0 torchvision-0.19.0 tqdm-4.67.1 transformers-4.47.0 triton-3.0.0 tzdata-2024.2 urllib3-2.2.3 uvicorn-0.32.1 uvloop-0.21.0 vllm-0.6.2 watchfiles-1.0.0 websockets-14.1 widgetsnbextension-4.0.13 xformers-0.0.27.post2 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give three types of computer graphics.\n",
      "Write Python code to solve the task:\n",
      "Let S be the concatenation of 10^{10} copies of the string 110. (For reference, the concatenation of 3 copies of 110 is 110110110.)\n",
      "We have a string T of length N.\n",
      "Find the number of times T occurs in S as a contiguous substring.\n",
      "\n",
      "-----Constraints-----\n",
      " - 1 \\leq N \\leq 2 \\times 10^5\n",
      " - T is a string of length N consisting of 0 and 1.\n",
      "\n",
      "-----Input-----\n",
      "Input is given from Standard Input in the following format:\n",
      "N\n",
      "T\n",
      "\n",
      "-----Output-----\n",
      "Print the number of times T occurs in S as a contiguous substring.\n",
      "\n",
      "-----Sample Input-----\n",
      "4\n",
      "1011\n",
      "\n",
      "-----Sample Output-----\n",
      "9999999999\n",
      "\n",
      "S is so long, so let us instead count the number of times 1011 occurs in the concatenation of 3 copies of 110, that is, 110110110. We can see it occurs twice:\n",
      " - 1 1011 0110\n",
      " - 1101 1011 0\n",
      "Can you provide information on the most effective methods for teaching language to young children?\n",
      "How do you solve and graph the compound inequality 2t + 1 > 13 or –18 > 7t + 3?\n",
      "What does it mean when we say \"Let $x$ be an element of the set $\\mathbb{R}$\"? Does $x$ represent only a single element of the set $\\mathbb{R}$? Or does $x$ represent all the elements of the set $\\mathbb{R}$ simultaneously at the same time? Some people say that if $x \\in \\mathbb{R}$ then $x$ is any real number; that means $x$ represents all real numbers. But if $x$ is any real number, then let's say $x = 1$; so $x$ is one, then how can it represent all real numbers? Please help me, I am very confused.\n",
      "How can I modify a C++ program to print out a Fibonacci sequence up to the nth number?\n",
      "Explain the concept of tail recursion using a programming language\n",
      "Write Python code to solve the task:\n",
      "Monocarp has drawn a tree (an undirected connected acyclic graph) and then has given each vertex an index. All indices are distinct numbers from 1 to n. For every edge e of this tree, Monocarp has written two numbers: the maximum indices of the vertices of the two components formed if the edge e (and only this edge) is erased from the tree.\n",
      "\n",
      "Monocarp has given you a list of n - 1 pairs of numbers. He wants you to provide an example of a tree that will produce the said list if this tree exists. If such tree does not exist, say so.\n",
      "\n",
      "Input\n",
      "\n",
      "The first line contains one integer n (2 ≤ n ≤ 1 000) — the number of vertices in the tree.\n",
      "\n",
      "Each of the next n-1 lines contains two integers a_i and b_i each (1 ≤ a_i < b_i ≤ n) — the maximal indices of vertices in the components formed if the i-th edge is removed.\n",
      "\n",
      "Output\n",
      "\n",
      "If there is no such tree that can produce the given list of pairs, print \"NO\" (without quotes).\n",
      "\n",
      "Otherwise print \"YES\" (without quotes) in the first line and the edges of the tree in the next n - 1 lines. Each of the last n - 1 lines should contain two integers x_i and y_i (1 ≤ x_i, y_i ≤ n) — vertices connected by an edge.\n",
      "\n",
      "Note: The numeration of edges doesn't matter for this task. Your solution will be considered correct if your tree produces the same pairs as given in the input file (possibly reordered). That means that you can print the edges of the tree you reconstructed in any order.\n",
      "\n",
      "Examples\n",
      "\n",
      "Input\n",
      "\n",
      "4\n",
      "3 4\n",
      "1 4\n",
      "3 4\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "YES\n",
      "1 3\n",
      "3 2\n",
      "2 4\n",
      "\n",
      "\n",
      "Input\n",
      "\n",
      "3\n",
      "1 3\n",
      "1 3\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "NO\n",
      "\n",
      "\n",
      "Input\n",
      "\n",
      "3\n",
      "1 2\n",
      "2 3\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "NO\n",
      "\n",
      "Note\n",
      "\n",
      "Possible tree from the first example. Dotted lines show edges you need to remove to get appropriate pairs. \n",
      "\n",
      "<image>\n",
      "Suggest some ways to recycle plastic.\n",
      "Can you provide an example of a merge conflict in a programming project and explain how to resolve it?\n",
      "Write a Python function `tag_string_to_tuple` that takes a string of comma-separated tags and returns a list of tuples. Each tuple contains a single tag and its position in the string. The tags may be repeated, and the position should be with respect to the original string.\n",
      "\n",
      "For example, if the input string is `\"a,b,c,d,a,b,c\"`, the function should return `[('a', 0), ('b', 1), ('c', 2), ('d', 3), ('a', 4), ('b', 5), ('c', 6)]`.\n",
      "How would the balance of a food web be impacted if a species were to go extinct in an ecosystem?\n",
      "Create a solution in Ada to the following:\n",
      "Sometimes, when testing whether the solution to a task (for example, here on Rosetta Code) is correct, the\n",
      "difference in floating point calculations between different language implementations becomes significant.\n",
      "\n",
      "For example, a difference between 32 bit and 64 bit floating point calculations may appear by\n",
      "about the 8th significant digit in base 10 arithmetic.\n",
      "\n",
      "\n",
      "\n",
      "Task\n",
      "\n",
      "Create a function which returns true if two floating point numbers are approximately equal.\n",
      "\n",
      "\n",
      "\n",
      "The function should allow for differences in the magnitude of numbers, so that, for example,\n",
      "\n",
      "100000000000000.01   may be approximately equal to   100000000000000.011,\n",
      "\n",
      "even though   100.01   is not approximately equal to   100.011.\n",
      "\n",
      "If the language has such a feature in its standard library, this may be used instead of a custom function.\n",
      "\n",
      "Show the function results with comparisons on the following pairs of values:\n",
      "\n",
      "     100000000000000.01,   100000000000000.011     (note: should return true)\n",
      "     100.01,   100.011                                                     (note: should return false)\n",
      "     10000000000000.001 / 10000.0,   1000000000.0000001000\n",
      "     0.001,   0.0010000001\n",
      "     0.000000000000000000000101,   0.0\n",
      "      sqrt(2) * sqrt(2),    2.0\n",
      "     -sqrt(2) * sqrt(2),   -2.0\n",
      "     3.14159265358979323846,   3.14159265358979324\n",
      "\n",
      "\n",
      "Answers should be true for the first example and false in the second, so that just rounding the numbers to a fixed number of decimals should not be enough. Otherwise answers may vary and still be correct. See the Python code for one type of solution.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Write a Python function to filter out all entities from a given set of entities (each with an attribute `.student_ids`) that have no relationship with any students (each with an attribute `.id`). Additionally, for each entity that is not filtered, calculate the number of students related to it.\n",
      "An object moves initially in a northerly direction at a speed of 5 m/s for 1 second, and then changes its direction to southerly at a speed of 3 m/s for 3 seconds. Calculate the object's average speed and average velocity over the entire duration.\n",
      "How do Toll-like receptors recognize and respond to specific microbial pathogens, and what are the downstream signaling pathways that are activated in innate immunity?\n",
      "Can you provide an example of a program using a loop construct to print the numbers from 1 to 10? None\n",
      "How do you draw an angle of 280 degrees in standard position?\n",
      "How are elementary particles detected and analyzed in particle physics experiments?\n",
      "How did the evolution of pterosaurs contribute to the development and refinement of flight in animals, and how did their physical characteristics enable them to achieve flight?\n",
      "You are tasked with implementing a function that calculates the remainder when dividing a number by 2. The function should take a natural number as input and return 0 if the number is even, and 1 if the number is odd. You are required to use the given code snippet as a reference for understanding the properties and operations of natural numbers in the context of this problem.\n",
      "\"How can technology be integrated effectively into chemistry education to enhance student understanding and engagement, despite the challenges and barriers that educators face in implementing it?\"\n",
      "How does a string preserve information about individual wave pulses during superposition, especially when interference results in zero net displacement, and how do these waves emerge unchanged?\n",
      "What are the seven attributes of a triangle and how do these attributes affect the triangle's relationship to other geometric shapes? Additionally, can you provide examples of real-world objects or structures that exhibit these attributes and their corresponding geometric properties?\n",
      "Solve the following problem step-by-step:\n",
      "Given the context and corresponding question, choose the correct answer from the options.\n",
      "\n",
      "Context: \n",
      "If, when the twenty-third century arrives, the history of the Mughal Empire is better known than that of our time, it will be because of our enthusiasm for electronically stored digital files. The contents of most digital media vanish long before words written on high-quality paper would, and they become obsolete and unusable even sooner due to rapid technological innovation. While information written on paper can be read directly, access to digital information is doubly indirect: the sequence of digits representing the information must be retrieved, and then that sequence must be decoded by the appropriate software.\n",
      "\n",
      "Question: \n",
      "Which one of the following statements most accurately expresses the main conclusion of the argument?\n",
      "\n",
      "Options: \n",
      "A. Information written on paper is more readily accessible than the contents of digital documents.\n",
      "B. Digitally stored information is particularly vulnerable because of the two-step process required to retrieve it.\n",
      "C. Historically important records from the present era may be lost because of the medium in which they are stored.\n",
      "D. The obsolescence brought about by ongoing technological innovation will make historical research increasingly difficult in the future.\n",
      "\n",
      "\n",
      "A circle has a center that falls on the line y = 7/9x + 7 and passes through (4, 5) and (8, 7). What is the equation of the circle?\n",
      "Create a function to convert a string containing numbers in scientific notation to an integer. The string may also contain decimal numbers.\n",
      "inputString: \"1.2345e10\"\n",
      "Detailed Instructions: Combine the given two facts to write a concluding fact. Note that there should be some parts of the first and second facts that are not mentioned in this conclusion fact. Your combined fact should be the result of a chain between the two facts. Chains form when two facts connect together to produce a concluding fact. An example of a chain is: \"pesticides cause pollution\" (fact1) + \"pollution can harm animals\" (fact2) → \"pesticides can harm animals\" (conclusion fact). Parts of the concluding fact overlap with the first and the second fact. To construct such a  concluding fact, a useful way is to borrow the subject from one fact and the ending conclusions from another fact.\n",
      "Q: Fact 1: Skin color is a polygenic trait. \n",
      "Fact 2: Skin color varies from grey to brown.\n",
      "A:\n",
      "How does the activation of T cells contribute to the immune response against a specific pathogen, and what are the mechanisms involved in this process?\n",
      "Write a Python program to swap two variables.\n",
      "Given a list of tuples with a first element `x` and a second element `y`, return a dictionary where the key is `x` and the value is a list of all `y` values paired with `x`. For example, if the input list is `[(1, \"A\"), (1, \"B\"), (2, \"C\")]`, the output dictionary would be `{1: [\"A\", \"B\"], 2: [\"C\"]}`.\n",
      "Write Python code to solve the task:\n",
      "Connected undirected graph without cycles is called a tree. Trees is a class of graphs which is interesting not only for people, but for ants too.\n",
      "\n",
      "An ant stands at the root of some tree. He sees that there are n vertexes in the tree, and they are connected by n - 1 edges so that there is a path between any pair of vertexes. A leaf is a distinct from root vertex, which is connected with exactly one other vertex.\n",
      "\n",
      "The ant wants to visit every vertex in the tree and return to the root, passing every edge twice. In addition, he wants to visit the leaves in a specific order. You are to find some possible route of the ant.\n",
      "\n",
      "Input\n",
      "\n",
      "The first line contains integer n (3 ≤ n ≤ 300) — amount of vertexes in the tree. Next n - 1 lines describe edges. Each edge is described with two integers — indexes of vertexes which it connects. Each edge can be passed in any direction. Vertexes are numbered starting from 1. The root of the tree has number 1. The last line contains k integers, where k is amount of leaves in the tree. These numbers describe the order in which the leaves should be visited. It is guaranteed that each leaf appears in this order exactly once.\n",
      "\n",
      "Output\n",
      "\n",
      "If the required route doesn't exist, output -1. Otherwise, output 2n - 1 numbers, describing the route. Every time the ant comes to a vertex, output it's index.\n",
      "\n",
      "Examples\n",
      "\n",
      "Input\n",
      "\n",
      "3\n",
      "1 2\n",
      "2 3\n",
      "3\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "1 2 3 2 1 \n",
      "\n",
      "Input\n",
      "\n",
      "6\n",
      "1 2\n",
      "1 3\n",
      "2 4\n",
      "4 5\n",
      "4 6\n",
      "5 6 3\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "1 2 4 5 4 6 4 2 1 3 1 \n",
      "\n",
      "Input\n",
      "\n",
      "6\n",
      "1 2\n",
      "1 3\n",
      "2 4\n",
      "4 5\n",
      "4 6\n",
      "5 3 6\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "-1\n",
      "In a fluid dynamics experiment using a Bernoulli air tunnel, you obtain the following measurements:\n",
      "\n",
      "Measurement 1 (fan off):\n",
      "Micrometer reading = -0.010 inches\n",
      "Transducer reading = 3.000 volts\n",
      "\n",
      "Measurement 2 (fan on):\n",
      "Micrometer reading = +0.500 inches\n",
      "Transducer reading = 3.586 volts\n",
      "\n",
      "(a) Develop a linear equation that relates transducer voltage (V, in volts) to pressure difference (ΔP, in Pa) based on the provided data.\n",
      "\n",
      "(b) Given Port #8 displays a transducer reading of 3.450V, use the equation from part (a) to convert this to a pressure differential in Pa. Calculate the air velocity at Port #8 using this pressure difference.\n",
      "\n",
      "(c) Determine the Mach number (M) for the air velocity at Port #8. Assume the flow is incompressible.\n",
      "\n",
      "(d) Apply the principle of continuity to find the average velocity at Port #2, considering the same assumptions as in part (c).\n",
      "Given a 10x10 grid of squares, where each square represents a sequential number from 0 to 99, how do you calculate the distance between any two squares? The distance is calculated by steps like a king in chess, which can move only one step adjacently or diagonally.\n",
      "Solve the following math problem step-by-step.\n",
      "Simplify your answer as much as possible. Present your final answer as \\boxed{Your Answer}.\n",
      "two trains are moving in opposite direction @ 60 kmph and 90 kmph . their lengths are 1.10 km and 0.9 km respectively . the time taken by the slower train to cross the faster train in seconds is\n",
      "\"How do human activities such as urbanization and deforestation affect the migration and breeding patterns of migratory animals in a specific region?\"\n",
      "How do you determine the correct Lewis structure for a compound like NO3-, and is it acceptable for the central atom to have a lone pair?\n",
      "How do steppe ecosystems and their unique species assemblages adapt to the changing climate conditions and human activities in their respective regions?\n",
      "Explain what a deadlock is in operating systems and elaborate on the necessary conditions for a deadlock to occur. Additionally, provide a real-world example of a deadlock situation and describe the steps that can be taken to prevent or resolve it. Implement a multi-threaded program in Python that simulates a deadlock situation, where two or more threads are waiting for resources held by each other. The program should output the steps taken to detect and resolve the deadlock, such as implementing a resource allocation algorithm or using synchronization primitives.\n",
      "Write a Python function `remove_overlapping_boxes` that takes a list of bounding boxes (integer tuples of the form (x, y, width, height)) as an argument and returns a list of non-overlapping boxes by sorting the list of boxes by their x-coordinates.\n",
      "Why does the temperature of boiling water in a pot on a stove remain at 100°C even after it has been boiling for an extended period?\n",
      "How can you write an inequality that expresses why the lengths 5 feet, 10 feet, and 20 feet cannot be used to make a triangle?\n",
      "How does the behavior of animals contribute to the transmission of diseases and what measures can be taken to minimize this risk?\n",
      "What is the purpose of the Comparable interface in Python and how can it be implemented in a class?\n",
      "Create an analogy to explain how a computer works.\n",
      "Explain \"partition problem\" and show how solving \"partition problem\" can solve \"3-SAT\" problem with examples and explain how partition problem is an NP-complete problem\n",
      "BEGININPUT\n",
      "BEGINCONTEXT\n",
      "page: https://link.to.website/?foo=i12939#fjfjq\n",
      "ENDCONTEXT\n",
      "In a recent study published by the prestigious Vintar Institute of Technology (VIT), researchers have discovered that Zorblatt berries, native to the remote island of Moltavio, could potentially revolutionize the way we produce energy. The research team, led by Dr. Elara Grintock, has been studying these unique berries for over three years and has made some remarkable findings.\n",
      "\n",
      "Zorblatt berries are small, purple fruits found exclusively on the island of Moltavio, located approximately 2,000 miles off the coast of Qalistan. These berries have an unusually high concentration of a compound called zorbonium, which has previously been shown to have extraordinary energy-producing properties. According to Dr. Grintock's research, one gram of zorbonium can generate up to 50 times more energy than an equivalent amount of coal.\n",
      "\n",
      "The process of extracting zorbonium from Zorblatt berries is relatively simple and cost-effective. Once harvested, the berries are crushed into a pulp, which is then filtered through a specialized membrane to separate the zorbonium from the other components of the berry. This concentrated zorbonium solution can then be used as a fuel source for various applications, including electricity generation and transportation.\n",
      "\n",
      "However, there are several concerns surrounding the use of Zorblatt berries for energy production. First and foremost, the limited availability of these berries poses a significant challenge. Moltavio is a small, isolated island with a fragile ecosystem, and it is unclear whether large-scale cultivation of Zorblatt berries would be sustainable or even possible without causing irreparable damage to the environment.\n",
      "\n",
      "Additionally, while the extraction process itself is straightforward, transporting the berries from Moltavio to other parts of the world could prove to be both expensive and logistically challenging. The island's remote location, combined with its lack of infrastructure, means that shipping costs would likely be high, potentially offsetting any economic benefits gained from using Zorblatt berries as an energy source.\n",
      "\n",
      "Finally, there is also concern about the potential impact on local communities in Moltavio. While the introduction of a new industry could bring much-needed jobs and economic growth to the region, it may also lead to cultural disruption and environmental degradation if not managed carefully.\n",
      "\n",
      "Despite these challenges, Dr. Grintock remains optimistic about the future of Zorblatt berries in the energy sector. She believes that further research and development will help address some of the concerns raised by her study and ultimately pave the way for a cleaner, more sustainable energy future.\n",
      "ENDINPUT\n",
      "BEGININSTRUCTION\n",
      "Name some benefits and drawbacks of Zorblatt berries in terms of energy production.  Include references.\n",
      "ENDINSTRUCTION\n",
      " \n",
      "In light of Newton's law of universal gravitation, can you provide a more comprehensive explanation of the relationship between the gravitational force and the masses of two objects? How can we further comprehend the inverse proportionality between the gravitational force and the square of the distance between the objects? Can you elaborate on how the application of this law could be extended to more complex real-world scenarios, such as the planetary orbits, the gravitational pull between celestial bodies, and the structure of the universe itself?\n",
      "Why are d-block elements called outer transition elements and f-block elements called inner transition elements?\n",
      "Tool available:\n",
      "[1] Python interpreter\n",
      "When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment.\n",
      "Solve the following math problem step-by-step.\n",
      "Simplify your answer as much as possible.\n",
      "set j consists of 18 consecutive even numbers . if the smallest term in the set is - 22 , what is the range of the positive integers in set j ?\n",
      "William Oughred invented which mathematical instrument in 1622?\n",
      "What is the answer?\n",
      "How do I evaluate the gradient (∇f) in the equation df = ∇f ⋅ dl, and what does it represent?\n",
      "How is the frequency of total solar eclipses being affected by the moon's recession from Earth? Provide the current rate at which total solar eclipses are decreasing, expressed in the number of total eclipses per 100 years.\n",
      "Can you explain the benefits and challenges of bilingual education in schools?\n",
      "What is the unique property that allows ice to float on water?\n",
      "A mixture of nitrogen and hydrogen gases is placed in a sealed container at 500 K. The initial partial pressure of nitrogen is 0.50 atm and that of hydrogen is 1.00 atm. The reaction N₂(g) + 3H₂(g) ⇌ 2NH₃(g) reaches equilibrium. If the equilibrium partial pressure of ammonia is 0.20 atm, what will be the sign of the change in Gibbs free energy, ΔG, for the reaction?\n",
      "Solve the following math problem step-by-step.\n",
      "Simplify your answer as much as possible. Present your final answer as \\boxed{Your Answer}.\n",
      "michael cashed a check for $ 1270 and received only $ 10 and $ 50 bills in return . during the course of a day , he used 15 bills and then lost the rest of the money . if the number of $ 10 bills used was either one more or one less than the number of $ 50 bills used , what is the minimum possible amount of money that was lost ?\n",
      "Write a code to get the user input for two numbers and print the sum of the two numbers.\n",
      "Write a Python function to remove all leading and trailing whitespace characters from a list of strings, and then split the strings into individual words if they contain spaces. If a word is repeated in the list, add an asterisk (*) after it as many times as it appears in the list. If a word is repeated in the same position in the list, only add one asterisk.\n",
      "\n",
      "Here's an example of how the function should work:\n",
      "\n",
      "```\n",
      "Input: [' a', 'b', 'c', '  d', '  d   ', ' a ', 'a']\n",
      "Output: ['a', 'b', 'c', 'd', 'd*', 'a*', 'a*']\n",
      "```\n",
      "\n",
      "Note that the order of the strings in the output list is maintained.\n",
      "Explain how to graph the equation #y = -2x - 1# using the slope-intercept form.\n",
      "Explain the link between climate change and ocean currents and circulation patterns.\n",
      "List the fundamental principles of calculus\n",
      "Solve the following math problem step-by-step.\n",
      "Simplify your answer as much as possible. Present your final answer as \\boxed{Your Answer}.\n",
      "In how many different ways can four students stand in a straight line if two of the students refuse to stand next to each other?\n",
      "Explain how gravity influences the trajectory of a projectile launched at an angle.\n",
      "Identify the type of bonding present in diamond and explain why it exhibits that type of bonding.\n",
      "A right triangle has a hypotenuse of length 10 cm and one other side of length 6 cm. Find the length of the third side.\n",
      "Consider a simple graph G with 8 vertices where each vertex has a degree of 3. Determine the girth of G.\n",
      "Summarize the civil war.\n",
      "Tyrah has six times as many pencils as Sarah has. Tim has eight times as many pencils as Sarah. If Tyrah has x pencils, Tim has 16. What is the value of unknown variable x? What is the value of unknown variable x?\n",
      "How does multiplying a vector by its transpose result in a matrix instead of a single product?\n",
      "How can parallax be used as a method to measure the distances of celestial objects?\n",
      "Let A = {1, 2, 3}. Find the size of the power set of A and compare it with the size of the set A itself. Show that the power set of A is always larger than the set A.\n",
      "What will be the output of the following Python program?\n",
      "\n",
      "```python\n",
      "numbers = [5, 10, 15, 20, 25]\n",
      "output = []\n",
      "\n",
      "for num in numbers:\n",
      "    if num % 2 == 0:\n",
      "        output.append(num * 2)\n",
      "    else:\n",
      "        output.append(num + 5)\n",
      "\n",
      "print(output)\n",
      "```\n",
      "Create a loop that prints the numbers 1 to 5.\n",
      "Write Python code to solve the task:\n",
      "Given a number **n**, return the number of positive odd numbers below **n**, EASY!\n",
      "\n",
      "Expect large Inputs!\n",
      "What physical characteristics can be used to classify birds into different groups?\n",
      "How does exposure to artificial light at night affect the mating behavior of a specific species of insect, and what are the potential consequences of this on their population dynamics and ecosystem functioning?\n",
      "Solve the following math problem step-by-step.\n",
      "Simplify your answer as much as possible. Present your final answer as \\boxed{Your Answer}.\n",
      "A sphere is inscribed in a cube. What is the ratio of the volume of the inscribed sphere to the volume of the cube? Express your answer as a common fraction in terms of $\\pi$.\n",
      "Given the sentence \"Two young children under a blue and yellow umbrella.\" is it true that \"Kids playing in the rain.\"? Now, let's be accurate as possible. Some thinking first:\n",
      "Explain how different types of rocks provide insights into Earth's past.\n",
      "Prove that the sum of the angles in any triangle always equals 180 degrees, using geometric reasoning.\n",
      "How has the evolution of antibiotic resistance in bacteria affected human health over time, and what can be done to minimize its impact?\n",
      "Write Python code to solve the task:\n",
      "Ã¢â¬â¹Given a number x, your task is to find if this number is Deficient number or not. A number x is said to be Deficient Number if sum of all the divisors of the number denoted by divisorsSum(x) is less than twice the value of the number x. And the difference between these two values is called the deficiency.\n",
      "Mathematically, if below condition holds the number is said to be Deficient:\n",
      "divisorsSum(x) < 2*x\n",
      "deficiency = (2*x) - divisorsSum(x)\n",
      "Example 1:\n",
      "Input: x = 21\n",
      "Output: YES \n",
      "Explanation: Divisors are 1, 3, 7 and\n",
      "21.Sum of divisors is 32. \n",
      "This sum is less than 2*21 or 42.\n",
      "Example 2:\n",
      "Input: x = 12\n",
      "Output: NO\n",
      "Explanation: Divisors are 1, 2, 3, 4,\n",
      "6 and 12.Sum of divisors is 28.\n",
      "This sum is not less than 2*12 or 24.\n",
      "Your Task:  \n",
      "You dont need to read input or print anything. Complete the function isDeficient() which takes x as input parameter and returns YES if the number is Deficient otherwise returns NO.\n",
      "Expected Time Complexity: O(sqrt(n))\n",
      "Expected Auxiliary Space: O(1)\n",
      "Constraints:\n",
      "1<= x <=10000000\n",
      "How do you express the area of a circle inscribed in a rectangle with length 4 times its width, denoted as x?\n",
      "In M.A. Armstrong's \"Basic Topology,\" Chapter 1, Problem 11(b) asks to visualize continuous deformations between spaces depicted in Figure 1.23. Specifically, consider a punctured torus (X) and two cylinders glued together over a square patch (Y). Describe a continuous deformation between these two spaces.\n",
      "Write Python code to solve the task:\n",
      "Given a String(only lower case letters) , check if any substring has occured Twice :\n",
      "\n",
      " Example : iwsagoodboody\n",
      "Here, substring  \"ood\" occurs twice.\n",
      "\n",
      "Output \"YES\"  if there is any such substring else output \"NO\" .(without qoutes)\n",
      "\n",
      "Input:\n",
      "\n",
      "First line of input consists of an integer T (1 ≤ T ≤ 100) ,  indicating the number of test cases. \n",
      "For each test case, there will be a string s (1 ≤ |s| ≤ 2000)\n",
      "\n",
      "Output:\n",
      "    Print \"YES\"  if there is any such substring else Print \"NO\" .(without quotes)\n",
      "\n",
      "SAMPLE INPUT\n",
      "3\n",
      "abcdefghi\n",
      "dogsbarkatdogs\n",
      "howtheydo\n",
      "\n",
      "SAMPLE OUTPUT\n",
      "NO\n",
      "YES\n",
      "YES\n",
      "What are the key terms in probability Probability theory is the branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms. Typically these axioms formalise probability in terms of a probability space, which assigns a measure taking values between 0 and 1, termed the probability measure, to a set of outcomes called the sample space. Any specified subset of the sample space is called an event. Central subjects in probability theory include discrete and continuous random variables, probability distributions, and stochastic processes (which provide mathematical abstractions of non-deterministic or uncertain processes or measured quantities that may either be single occurrences or evolve over time in a random fashion). Although it is not possible to perfectly predict random events, much can be said about their behavior. Two major results in probability theory describing such behaviour are the law of large numbers and the central limit theorem.\n",
      "Write Python code to solve the task:\n",
      "Given a string consisting of only numbers from 0 to 9, consider the operation of creating a new string from that string according to the following rules. Read the given string one character at a time from the left end. Go, if the same number a continues r, write the number r and the number a in this order without separating them with a space. Read to the right end of the given character string, and what is on the way to the end of the last writing Even if there are times of writing, all of them are counted as one operation. For the second and subsequent operations, the same operation is performed with the character string written out by the previous operation as the given character string. For example, \"122244\" If the character string \"\" is given, the character string obtained by one operation is \"113224\" and \"44444444444\" (11) because one 1, three 2, two 4s are given in order from the left end. In the case of 4), the obtained character string is “114”.\n",
      "\n",
      "Create a program that outputs a string obtained by performing the above operation n times on a given string of 100 characters or less, where n ≤ 20.\n",
      "\n",
      "The input data consists of two lines, the first line contains the number of operations n, and the second line contains the first character string.\n",
      "\n",
      "Input example\n",
      "---\n",
      "Five\n",
      "11\n",
      "Output example\n",
      "13112221\n",
      "\n",
      "input\n",
      "\n",
      "The input consists of multiple datasets. Input ends when n is 0. The number of datasets does not exceed 5.\n",
      "\n",
      "output\n",
      "\n",
      "For each data set, the character string that has been operated the specified number of times is output on one line.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Example\n",
      "\n",
      "Input\n",
      "\n",
      "5\n",
      "11\n",
      "5\n",
      "11\n",
      "0\n",
      "\n",
      "\n",
      "Output\n",
      "\n",
      "13112221\n",
      "13112221\n",
      "1. What would it feel like to squeeze an Earth-sized object with a density similar to that of an orange (approximately 4 g/cm³), considering its layered structure of a thin crust, solid land masses, and a molten core?\n",
      "\n",
      "2. How would the physics of squeezing an Earth-sized object differ if we scaled ourselves up instead, making the Earth fit comfortably in the palm of our hand, while ignoring the challenges of scaling a human being?\n",
      "Q: What happens between particles with opposite charges?   A:\n",
      "Answer:\n",
      "Write Python code to solve the task:\n",
      "Given a string, S.The string can contain small case English letters or '?'. You can replace '?' with any small English letter. Now if it is possible to make the string S a palindrome after replacing all '?' then find the palindromic string with a minimum ascii sum of the absolute difference of adjacent characters. Otherwise, return -1.\n",
      "Example 1:\n",
      "Input: S = a???c??c????\n",
      "Output: 4\n",
      "Explanation:\n",
      "We can see that we can make the string\n",
      "palindrome. Now to get minimum ascii sum we should\n",
      "replace all the '?' between 'a' and 'c' with\n",
      "'b' and all the '?' between two 'c' with 'c'.\n",
      "So after replacing all the '?' the string: \n",
      "abbbccccbbba.\n",
      "The sum of differences of adjacent characters is 4.   \n",
      "Example 2:\n",
      "Input: S = a???c??c???c\n",
      "Output: -1\n",
      "Explanation:\n",
      "It is not possible to make the string palindrome.\n",
      "Your Task:\n",
      "You don't need to read input or print anything. Your task is to complete the function minimumSum() which takes a string S input parameter and returns an integer denoting the sum of differences of adjacent characters. If it is not possible to make string palindrome, return -1. \n",
      "Expected Time Complexity: O(N)\n",
      "Expected Auxiliary Space: O(1)\n",
      "Constraints:\n",
      "1 <= |S| <= 10^{5}\n",
      "Point A is at (-2, 9) and point B is at (-1, 4). Point A is rotated (3pi)/2 clockwise about the origin. What are the new coordinates of point A and by how much has the distance between points A and B changed?\n",
      "Which two-word Latin phrase, meaning \"seize the day,\" encourages people to make the most of their present opportunities?\n",
      "How does the brain's ability to undergo neuroplasticity impact an individual's learning and memory retention?\n",
      "How does the condition $|Z|=1$ in the complex plane represent a circle with its center at the origin?\n",
      "Sixteen is 64$\\%$ of what number? \n",
      "Write a Python program to check if a given number is a multiple of another number.\n",
      "Solve the following math problem step-by-step.\n",
      "Simplify your answer as much as possible. Present your final answer as \\boxed{Your Answer}.\n",
      "Find the number of moles of CH3Cl formed on combining 1 mole of CH4 and 1 mole of Cl2\n",
      "What was the impact of the Civil Rights Movement in the United States?\n",
      "How do you derive the formula for the volume of a sphere?\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "\n",
    "dataset_name = \"mlabonne/FineTome-100k\"\n",
    "dataset = load_dataset(dataset_name, split=\"all\").shuffle(seed=42)\n",
    "messages = dataset.map(\n",
    "    lambda row: {\"role\": \"user\", \"content\": next((item[\"value\"] for item in row[\"conversations\"] if item[\"from\"] == \"human\"), None)},\n",
    "    remove_columns=dataset.column_names\n",
    ")\n",
    "\n",
    "messages = list(messages)[:100]\n",
    "\n",
    "for message in messages:\n",
    "    print(message['content'])\n",
    "\n",
    "orpo_path = \"orpo.json\"\n",
    "llama_path = \"llama.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/lab/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: NotImplemented is not recognized, so we'll default to None\n",
      "==((====))==  Unsloth 2024.12.2: Fast Llama patching. Transformers:4.47.0.\n",
      "   \\\\   /|    GPU: NVIDIA H100 80GB HBM3 MIG 1g.20gb. Max memory: 19.625 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.0+cu121. CUDA: 9.0. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.2 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import json, time\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"EITD/orpo_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = 2048,\n",
    "    dtype = NotImplemented,\n",
    "    load_in_4bit = False,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "responses = []\n",
    "for message in messages:\n",
    "    start = time.time()        \n",
    "    inputs = tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            message['content'],\n",
    "            message['content'], # input\n",
    "            \"\", # output - leave this blank for generation!\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True, temperature = 1.5, min_p = 0.1)\n",
    "    \n",
    "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    end = time.time()         \n",
    "\n",
    "    response = response.split(\"Response\")[-1].strip()\n",
    "    responses.append({'time': end - start, 'response': response})\n",
    "\n",
    "with open(orpo_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: NotImplemented is not recognized, so we'll default to None\n",
      "==((====))==  Unsloth 2024.12.2: Fast Llama patching. Transformers:4.47.0.\n",
      "   \\\\   /|    GPU: NVIDIA H100 80GB HBM3 MIG 1g.20gb. Max memory: 19.625 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.0+cu121. CUDA: 9.0. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import json, time\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-1B-Instruct\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = 2048,\n",
    "    dtype = NotImplemented,\n",
    "    load_in_4bit = False,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "responses = []\n",
    "for message in messages:\n",
    "    start = time.time()        \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        [message],\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True, # Must add for generation\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(input_ids = inputs, max_new_tokens = 128, use_cache = True, temperature = 1.5, min_p = 0.1)\n",
    "    \n",
    "    response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    end = time.time()         \n",
    "\n",
    "    response = response.split(\"assistant\")[-1].strip()\n",
    "    responses.append({'time': end - start, 'response': response})\n",
    "\n",
    "with open(llama_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/lab/lib/python3.12/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5c322002054a54b1ec410442095d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04efe0b348ae464e9d2ec1c99c8c9444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/flowaicom/Flow-Judge-v0.1-AWQ:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-06 01:53:30 awq_marlin.py:90] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.\n",
      "WARNING 12-06 01:53:30 config.py:389] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 12-06 01:53:30 llm_engine.py:226] Initializing an LLM engine (v0.6.1.dev238+ge2c6e0a82) with config: model='flowaicom/Flow-Judge-v0.1-AWQ', speculative_config=None, tokenizer='flowaicom/Flow-Judge-v0.1-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=flowaicom/Flow-Judge-v0.1-AWQ, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0c596d9fe74b83af8868d10c030981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd031e3d66b94d3ba1a99266011c6b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93089667e1504140a16b569d7851e2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb01700fc3574b2ea761d844d44ea787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b18f2c7c46747b68379e06309be74d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0052191b0149ceaa2fa52e1d051942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/193 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-06 01:53:33 model_runner.py:1014] Starting to load model flowaicom/Flow-Judge-v0.1-AWQ...\n",
      "INFO 12-06 01:53:33 weight_utils.py:242] Using model weights format ['*.safetensors']\n",
      "INFO 12-06 01:53:33 weight_utils.py:287] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4e0c05d05b4f6abcfc153ed8337810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-06 01:53:35 model_runner.py:1025] Loading model weights took 2.1717 GB\n",
      "INFO 12-06 01:53:37 gpu_executor.py:122] # GPU blocks: 2456, # CPU blocks: 682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/100 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-06 01:53:45 scheduler.py:1439] Sequence group 35 is preempted by PreemptionMode.RECOMPUTE mode because there is not enough KV cache space. This can affect the end-to-end performance. Increase gpu_memory_utilization or tensor_parallel_size to provide more KV cache memory. total_num_cumulative_preemption=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s, est. speed input: 2076.53 toks/s, output: 489.04 toks/s]\n",
      "Processed prompts: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s, est. speed input: 2087.92 toks/s, output: 508.46 toks/s]\n"
     ]
    }
   ],
   "source": [
    "from flow_judge import Llamafile, EvalInput, FlowJudge, Vllm\n",
    "from flow_judge.metrics import RESPONSE_FAITHFULNESS_5POINT\n",
    "import json\n",
    "\n",
    "# Initialize the model\n",
    "judge = Vllm()\n",
    "\n",
    "# Initialize the judge\n",
    "faithfulness_judge = FlowJudge(\n",
    "    metric=RESPONSE_FAITHFULNESS_5POINT,\n",
    "    model=judge\n",
    ")\n",
    "\n",
    "# Create a list of inputs and outputs\n",
    "inputs_batch = [\n",
    "    [\n",
    "        {\"query\": message[\"content\"]},\n",
    "        {\"context\": \"\"},\n",
    "    ]\n",
    "    for message in messages\n",
    "]\n",
    "\n",
    "def judge(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    outputs_batch = [{\"response\": item[\"response\"]} for item in data]\n",
    "\n",
    "    # Create a list of EvalInput\n",
    "    eval_inputs_batch = [EvalInput(inputs=inputs, output=output) for inputs, output in zip(inputs_batch, outputs_batch)]\n",
    "\n",
    "    # Run the batch evaluation\n",
    "    results = faithfulness_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        data[i]['score'] = result.score\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "judge(orpo_path)\n",
    "judge(llama_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orpo metrics:\n",
      "Avg Inference Time: 1.4090176939964294\n",
      "Avg Score: 3.24\n",
      "Llama metrics:\n",
      "Avg Inference Time: 1.1835386228561402\n",
      "Avg Score: 3.57\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    time_sum = 0\n",
    "    score_sum = 0\n",
    "    for item in data:\n",
    "        time_sum += item['time']\n",
    "        score_sum += item['score']\n",
    "\n",
    "    print(\"Avg Inference Time:\", time_sum / len(data))\n",
    "    print(\"Avg Score:\", score_sum / len(data))\n",
    "\n",
    "print(\"Orpo metrics:\")\n",
    "compute_metrics(orpo_path)\n",
    "print(\"Llama metrics:\")\n",
    "compute_metrics(llama_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
